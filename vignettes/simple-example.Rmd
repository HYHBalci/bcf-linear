---
title: "A Simple Example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A Simple Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(bcf2)
library(ggplot2)
```

## Simulate data

First, we simulate some data for testing.  This data set has three covariates $X$, which we divide into two control variables -- that is, variables related to $y$ -- and one effect moderator -- that is, a variable that changes the relationship between $y$ and the treatment effect $\tau$.

We draw the $X$s from a standard normal distribution and generate each unit's outcome, $\mu_i$, as a function of these covariates.  Each unit's probability of joining the intervention, $\pi_i$, is also a function of $\mu_i$, so that units with larger outcomes are more likely to participate in the intervention.  We then assign units to treatment ($z_i = 1$) or comparison ($z_i = 0$) as a function of $\pi_i$.

Then we generate the true treatment effect for each unit, $\tau_i$.  As noted above, $\tau_i$ is a function of $X_3$.  the observed outcome, $y_i$, is a function of $\mu_i$, $\tau_i$, and a random error term $\sigma$.

```{r data creation}
set.seed(1)

p <- 3 # two control variables and one effect moderator
n <- 20
n_burn <- 100
n_sim <- 150


x <- matrix(rnorm(n*p), nrow=n)

weights <- 1.0*rep(1, n)


# create targeted selection, whereby a unit's likelihood of joining the intervention (pi) is related to its expected outcome (mu)
q <- -1*(x[,1]>(x[,2])) + 1*(x[,1]<(x[,2])) -0.1

# generate treatment variable
pi <- pnorm(q)
z <- rbinom(n,1,pi)

# tau is the true treatment effect. It varies across practices as a function of
# X3, the effect moderator
tau <- 1/(1 + exp(-x[,3]))

# generate the response using q, tau and z
mu <- (q + tau*z)

# set the noise level relative to the expected mean function of Y
sigma <- diff(range(q + tau*pi))/8

# draw the response variable with additive error
y <- mu + sigma*rnorm(n)
```

## Fit BCF model

In this data set we have observed $y_i$, $x_i$, and $\pi_i$ values to which we can fit our BCF model.  We can then compare the $\hat{\tau}_i$ estimates from BCF to the true $\tau_i$ from the data-generating process.

```{r model}
bcf_out <- bcf2::bcf(y            = y,
                 z                = z,
                 x_control        = x,
                 x_moderate       = x,
                 pihat            = pi,
                 nburn            = n_burn,
                 nsim             = n_sim,
                 w                = weights,
                 n_chains         = 4,
                 n_chain_clusters = 2,
                 random_seed      = 1,
                 update_interval  = 1)

cat("BCF run complete\n")
```

```{r diagnostics}
bcf2::summarise_bcf(bcf_out)
```

## Examine output

Now that we've successfully fit our model, let's see what we can do with the output.  First, in this simulation setting, let's compare the fitted treatment effect estimates $\hat{\tau}_i$ to the true treatment effects $\tau_i$.


### Estimates vs. true treatment effects

```{r}
ggplot(NULL, aes(x = tau, y = colMeans(bcf_out$tau))) +
  geom_abline() +
  geom_point() +
  ylab("tau estimate")
```

Clearly, BCF correctly recovers the true treatment effects in this simple example.  We can also calculate how well the BCF treatment effect estimates explain variation in the true treatment effects.
```{r}
tau_fit <- lm(tau ~ colMeans(bcf_out$tau))
coef <- summary(tau_fit)$coef[2,"Estimate"]

## LVF added code to extract the adjusted R2
adjR2 <- summary(tau_fit)$adj.r.squared
```
Our estimates $\hat{\tau}_i$ explain `r round(adjR2, 2)*100`% of the variation in the $\tau_i$, reaffirming the idea that BCF provides accurate treatment effect estimates.

### Distribution of treatment effects

Now that we have confidence in BCF's estimates of unit-specific treatment effects, we examine the results more closely.  First we consider the distribution of unit-specific treatment effects, to see how differently the treatment affects different units.  This plot shows the impact estimate and 95 percent credible interval for each unit, arranged from the smallest (most negative) impact to the largest (most positive).

```{r, echo = FALSE, eval = FALSE}
ggplot(NULL, aes(x = 1:(4*n_sim), y = bcf_out$tau[,1])) +
  geom_line() +
  ylab("tau estimate for unit 1") +
  xlab("draws")
```

```{r}
# LVF added this code to show distribution of unit-specific treatment effects, with 95% CIs.
tau_ests <- data.frame(Mean = colMeans(bcf_out$tau),
                       Low95 = apply(bcf_out$tau, 2, function(x) quantile(x, 0.025)),
                       Up95 = apply(bcf_out$tau, 2, function(x) quantile(x, 0.975))) %>%
  arrange(desc(Mean)) %>%
  mutate(id = 1:ncol(bcf_out$tau))

ggplot(tau_ests, aes(x = id, y = Mean)) +
  theme_bw() +
  geom_pointrange(aes(ymin = Low95, ymax = Up95), color = "blue") +
  geom_vline(xintercept = 0, color = "black") +
  ylab("Unit-Specific Treatment Effect") +
  xlab("Unit Number") +
  coord_flip()
  
```


### Identifying possible subgroups

The BCF model obtains more accurate treatment effect estimates than other approaches in part by considering more flexible effect modification relationships with more possible effect modifiers.  These relationships are often of substantive interest; researchers want to know what characteristics are associated with higher or lower impacts.  However, because the BCF model is difficult to interpret, we cannot simply look at the coefficients on the effect modifiers to determine which characteristics drive the impacts.  Instead, we can use existing techniques to look for patterns in the unit-specific treatment effects, linking each unit's treatment effect to its background characteristics.

Hill (2010) recommends searching for patterns by fitting a CART model where the response variable is the estimated treatment effects from the BCF fit and the predictor variables are the effect modifiers used to fit the BCF model.  The resulting tree identifies characteristics that strongly predict impacts, which are strong candidate subgroup variables.  However, because the CART fit does not account for the uncertainty in the treatment effect estimates, it is possible that tree splits do not identify characteristics that create subgroups with meaningfully different impacts.  To determine whether impacts differ meaningfully based on a characteristic, we can look back at the posterior draws from the BCF model.

Here we skip the CART fit step and show just a comparison of the impacts for units in the top quartile of $X_3$ vs. impacts for units in the bottom quartile of $X_3$, which we know to be a strong effect modifier because we specified it as such in the data generation step.

```{r}
q1 <- x[,3] < quantile(x[,3], 0.25)
q4 <- x[,3] > quantile(x[,3], 0.75)

q1Taus <- bcf_out$tau[,q1]
q4Taus <- bcf_out$tau[,q4]

wq1Taus <- apply(q1Taus, 1, weighted.mean, weights[q1])
wq4Taus <- apply(q4Taus, 1, weighted.mean, weights[q4])

groupTaus <- data.frame(taus     = c(wq1Taus, wq4Taus),
                        quartile = c(rep("q1", 4*n_sim), rep("q4", 4*n_sim)))

ggplot(groupTaus, aes(taus, fill = quartile, color = quartile)) +
  geom_density(alpha = 0.5)
```

[add text here showing what we found]