---
title: "Prediction with BCF"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A Simple Example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this vignette, we show how to use the `bcf` package to fit a model and use the fitted object to predict estimates for new data.

[LVF: suppressed warnings and messages in this block, per JG's recommendation]
```{r setup, warning=FALSE, message = FALSE}
library(bcf2)
library(latex2exp)
library(ggplot2)
```

[LVF: Per our discussion on 12/30/2019, let's delete the text introducing this section and hide the code. Suggested alternative text:

We will fit the model to simulated data, following exactly the same process as in the main vignette.  For that reason, we do not show the data generation steps here.]

## Simulate data

First, we simulate some data for testing. This data set has three covariates $X$, which we divide into two control variables -- that is, two covariates related to the outcome, $y$ -- and one effect moderator -- that is, a covariates related to the treatment effect, $\tau$.

We draw three random $X$s for each unit and generate each unit's expected outcome without treatment, $\mu_i$, as a function of $x^{(1)}_i$ and $x^{(2)}_i$. Each unit's probability of joining the intervention, $\pi_i$, is also a function of $\mu_i$, so that units with larger responses are more likely to participate in the intervention. We then assign units to treatment ($z_i = 1$) or comparison ($z_i = 0$) as a function of $\pi_i$.

Then we generate the true treatment effect for each unit, $\tau_i$. As noted above, $\tau_i$ is a function of $x^{(3)}_i$. The observed outcome, $y_i$, is a function of $\mu_i$, $\tau_i$, a random error term $\sigma$, and weights $w$ if applicable.

```{r, echo = FALSE}
set.seed(1)

## Training data

p <- 3 # two control variables and one effect moderator
n <- 100
n_burn <- 2000
n_sim <- 1500

x <- matrix(rnorm(n*p), nrow=n)
weights <- abs(rnorm(n))

# create targeted selection, whereby a practice's likelihood of joining the intervention (pi) is related to their expected outcome (mu)
q <- -1*(x[,1]>(x[,2])) + 1*(x[,1]<(x[,2])) -0.1

# generate treatment variable
pi <- pnorm(q)
z <- rbinom(n,1,pi)

# tau is the true treatment effect. It varies across practices as a function of
# X3, the effect moderator
tau <- (1/(1 + exp(-x[,3])))

mu <- q

# generate the response using q, tau and z
y_noiseless <- mu + tau*z

# set the noise level relative to the expected mean function of Y
sigma <- diff(range(mu + tau*pi))/8

# draw the response variable with additive error
y <- y_noiseless + sigma*rnorm(n)/sqrt(weights)

## Testing data (N = 50)
x_pred  <- matrix(rnorm(50*p), nrow=50)
x_pred[46:50,3] <- c(-3.1, -2.9, 2.76, 2.8, 2.85) # including some X3s outside of range
q_pred  <- -1*(x_pred[,1]>(x_pred[,2])) + 1*(x_pred[,1]<(x_pred[,2])) - 0.1
pi_pred <- pnorm(q_pred)
z_pred  <- rbinom(50,1, pi_pred)
```

## Fitting BCF

We now fit a BCF model to the simulated data.  This is the same model as we fit in the main vignette. 

```{r}
bcf_out <- bcf2::bcf(y               = y,
                     z               = z,
                     x_control       = x,
                     x_moderate      = x,
                     pihat           = pi,
                     nburn           = n_burn,
                     nsim            = n_sim,
                     w               = weights,
                     n_chains        = 2,
                     update_interval = 1)
```


## Predicting using BCF

We now use our testing Xs for prediction. [LVF: Should we move the code that generates the testing Xs down to this block?  Otherwise, since we're hiding the data generation code, this line won't make sense.  I'd recommend putting the creating of the x_pred in its own block with some explanatory text about how we're generating the Xs, specifically mentioning that we're including values outside the range of Xs used to fit the original model as a way of gauging out-of-sample error.]

[LVF: Do we need to explain the function arguments at all?]

```{r}
pred_out = bcf2::predict(bcf_out=bcf_out,
                         x_predict_control=x_pred,
                         x_predict_moderate=x_pred,
                         pi_pred=pi_pred,
                         z_pred=z_pred,
                         save_tree_directory = '..')
```

## Comparison

Let's compare the results of our training and testing data. We will show the estimated treatment effects for training and test observations as a function of $x_3$, which is an effect modifier.

```{r}
lower <- c(apply(bcf_out$tau, 2, quantile, 0.025), apply(pred_out$tau, 2, quantile, 0.025))
upper <- c(apply(bcf_out$tau, 2, quantile, 0.975), apply(pred_out$tau, 2, quantile, 0.975))
group <- factor(c(rep("training", n), rep("testing", 50)))

ggplot(NULL, aes(x = c(x[,3], x_pred[,3]), y = c(colMeans(bcf_out$tau), colMeans(pred_out$tau)), color = group)) +
  geom_pointrange(aes(ymin = lower, ymax = upper), alpha = 0.5) +
  xlab(TeX("$x_3$")) +
  ylab(TeX("$\\hat{\\tau}$")) +
  coord_flip()
```

The estimates for testing observations have treatmentent effects well within the range of the treatment effects for training observations, even though the test data set contains more extreme values of $x_3$. It is reassuring that these observations' treatment effects still fall within the expected range, suggesting that this model is not overly vulnerable to out-of-sample prediction error.